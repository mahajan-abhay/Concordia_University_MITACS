{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhay Mahajan\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import matutils , models , corpora\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = pd.read_pickle('english_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg = df_english.loc[df_english['sentiment'] == 0]\n",
    "df_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling - Attempt #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(df_neg['reviews']).toarray()\n",
    "features = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_cv , columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>younger</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows  99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1   2   3   4   5   6   7   8   9   ...  89  90  91  92  93  94  \\\n",
       "013       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "04        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "10        0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   \n",
       "15        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "20        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "...      ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "year      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "years     0   0   0   0   0   0   1   0   0   0  ...   0   0   0   0   0   0   \n",
       "yet       0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "younger   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "zero      0   0   0   0   0   0   0   0   0   0  ...   1   0   0   0   0   0   \n",
       "\n",
       "         95  96  97  98  \n",
       "013       0   0   0   0  \n",
       "04        0   0   0   0  \n",
       "10        0   0   0   0  \n",
       "15        0   0   0   0  \n",
       "20        0   0   0   0  \n",
       "...      ..  ..  ..  ..  \n",
       "year      0   0   0   0  \n",
       "years     0   0   0   0  \n",
       "yet       0   0   0   0  \n",
       "younger   0   0   0   0  \n",
       "zero      0   0   0   0  \n",
       "\n",
       "[785 rows x 99 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the major input for gensim is Term Document Matrix\n",
    "term_document_matrix = df.transpose()\n",
    "term_document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert our Term Document Matrix into a new format which is used by gensim\n",
    "# i.e. Term Document Matrix -> Sparse Matrix \n",
    "# and then Sparse Matrix -> Gensim Corpus\n",
    "\n",
    "sparse_matrix = scipy.sparse.csr_matrix(term_document_matrix)\n",
    "corpus = matutils.Sparse2Corpus(sparse_matrix)  # Converts a matrix in scipy.sparse format into a streaming gensim corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "id2word = corpora.Dictionary([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"park\" + 0.016*\"kids\" + 0.011*\"much\" + 0.010*\"nice\" + 0.010*\"good\" + 0.010*\"like\" + 0.008*\"really\" + 0.007*\"water\" + 0.007*\"little\" + 0.007*\"place\"'),\n",
       " (1,\n",
       "  '0.021*\"park\" + 0.011*\"nice\" + 0.011*\"small\" + 0.008*\"water\" + 0.006*\"one\" + 0.006*\"good\" + 0.005*\"area\" + 0.005*\"get\" + 0.005*\"could\" + 0.005*\"entrance\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 2\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=40)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"park\" + 0.013*\"nice\" + 0.010*\"good\" + 0.010*\"water\" + 0.009*\"also\" + 0.008*\"place\" + 0.008*\"could\" + 0.007*\"much\" + 0.007*\"like\" + 0.007*\"one\"'),\n",
       " (1,\n",
       "  '0.031*\"park\" + 0.014*\"kids\" + 0.013*\"nice\" + 0.010*\"much\" + 0.009*\"small\" + 0.008*\"view\" + 0.008*\"dog\" + 0.007*\"around\" + 0.006*\"little\" + 0.006*\"next\"'),\n",
       " (2,\n",
       "  '0.011*\"like\" + 0.009*\"go\" + 0.009*\"kids\" + 0.009*\"good\" + 0.008*\"bad\" + 0.008*\"fun\" + 0.008*\"people\" + 0.008*\"water\" + 0.008*\"small\" + 0.007*\"little\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=40)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.032*\"park\" + 0.020*\"nice\" + 0.012*\"small\" + 0.012*\"bad\" + 0.008*\"much\" + 0.008*\"go\" + 0.008*\"well\" + 0.008*\"walk\" + 0.008*\"take\" + 0.008*\"close\"'),\n",
       " (1,\n",
       "  '0.019*\"like\" + 0.015*\"good\" + 0.015*\"park\" + 0.011*\"views\" + 0.011*\"place\" + 0.011*\"nice\" + 0.008*\"could\" + 0.008*\"use\" + 0.008*\"theres\" + 0.008*\"visitors\"'),\n",
       " (2,\n",
       "  '0.023*\"park\" + 0.015*\"severe\" + 0.015*\"weekend\" + 0.015*\"spend\" + 0.015*\"friends\" + 0.008*\"well\" + 0.008*\"full\" + 0.008*\"clean\" + 0.008*\"also\" + 0.008*\"water\"'),\n",
       " (3,\n",
       "  '0.015*\"small\" + 0.015*\"good\" + 0.010*\"park\" + 0.010*\"little\" + 0.010*\"looking\" + 0.010*\"water\" + 0.010*\"walk\" + 0.010*\"picnic\" + 0.010*\"area\" + 0.010*\"point\"'),\n",
       " (4,\n",
       "  '0.036*\"view\" + 0.036*\"point\" + 0.027*\"park\" + 0.018*\"small\" + 0.018*\"much\" + 0.018*\"forest\" + 0.018*\"theres\" + 0.018*\"next\" + 0.018*\"dog\" + 0.018*\"mini\"'),\n",
       " (5,\n",
       "  '0.020*\"nice\" + 0.014*\"also\" + 0.014*\"water\" + 0.014*\"park\" + 0.012*\"little\" + 0.012*\"tables\" + 0.012*\"kids\" + 0.009*\"picnic\" + 0.009*\"since\" + 0.006*\"like\"'),\n",
       " (6,\n",
       "  '0.027*\"nice\" + 0.016*\"park\" + 0.011*\"great\" + 0.011*\"middle\" + 0.011*\"picnic\" + 0.011*\"soccer\" + 0.011*\"right\" + 0.011*\"really\" + 0.011*\"another\" + 0.011*\"live\"'),\n",
       " (7,\n",
       "  '0.027*\"kids\" + 0.024*\"park\" + 0.024*\"much\" + 0.017*\"always\" + 0.010*\"like\" + 0.010*\"could\" + 0.010*\"one\" + 0.010*\"french\" + 0.010*\"waiting\" + 0.010*\"entrance\"'),\n",
       " (8,\n",
       "  '0.019*\"people\" + 0.013*\"parc\" + 0.013*\"jumping\" + 0.013*\"amazing\" + 0.013*\"way\" + 0.013*\"get\" + 0.007*\"like\" + 0.007*\"bad\" + 0.007*\"stuck\" + 0.007*\"piece\"'),\n",
       " (9,\n",
       "  '0.031*\"kids\" + 0.023*\"water\" + 0.018*\"place\" + 0.018*\"good\" + 0.018*\"really\" + 0.018*\"park\" + 0.014*\"like\" + 0.014*\"well\" + 0.014*\"must\" + 0.014*\"put\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 10\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=10, passes=40)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling - Attempt #2 (Nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abhay\n",
      "[nltk_data]     Mahajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Abhay Mahajan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>things park areas dog enclosure tables kids vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>weekend friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>blocks litter cans recondition mode attachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>potiential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>park care grounds outremont dissapointing sign...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews\n",
       "3   things park areas dog enclosure tables kids vi...\n",
       "26                                    weekend friends\n",
       "47     blocks litter cans recondition mode attachment\n",
       "57                                         potiential\n",
       "76  park care grounds outremont dissapointing sign..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg_2 = df_neg\n",
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(df_neg_2['reviews'].apply(nouns))\n",
    "data_nouns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_noun = CountVectorizer(stop_words = stop_words)\n",
    "data_cv_noun = cv_noun.fit_transform(data_nouns['reviews']).toarray()\n",
    "features_noun = cv_noun.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data_cv_noun , columns = features_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document_matrix_noun = df2.transpose()\n",
    "term_document_matrix_noun\n",
    "sparse_matrix_noun = scipy.sparse.csr_matrix(term_document_matrix_noun)\n",
    "corpus_noun = matutils.Sparse2Corpus(sparse_matrix_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_noun = corpora.Dictionary([features_noun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.054*\"park\" + 0.020*\"water\" + 0.013*\"area\" + 0.011*\"kids\" + 0.011*\"walk\" + 0.009*\"entrance\" + 0.009*\"years\" + 0.009*\"parents\" + 0.007*\"day\" + 0.007*\"signs\"'),\n",
       " (1,\n",
       "  '0.031*\"kids\" + 0.023*\"park\" + 0.016*\"place\" + 0.016*\"water\" + 0.012*\"views\" + 0.012*\"view\" + 0.010*\"theres\" + 0.010*\"tables\" + 0.010*\"point\" + 0.007*\"things\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 2\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=2, passes=80)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.035*\"park\" + 0.013*\"place\" + 0.013*\"kids\" + 0.010*\"area\" + 0.010*\"day\" + 0.010*\"weekend\" + 0.010*\"water\" + 0.007*\"walk\" + 0.007*\"food\" + 0.007*\"information\"'),\n",
       " (1,\n",
       "  '0.051*\"park\" + 0.017*\"place\" + 0.017*\"views\" + 0.016*\"view\" + 0.013*\"theres\" + 0.013*\"point\" + 0.013*\"water\" + 0.010*\"dog\" + 0.010*\"tables\" + 0.010*\"space\"'),\n",
       " (2,\n",
       "  '0.043*\"kids\" + 0.030*\"water\" + 0.030*\"park\" + 0.011*\"tables\" + 0.011*\"bit\" + 0.008*\"signs\" + 0.008*\"walk\" + 0.008*\"area\" + 0.008*\"parents\" + 0.008*\"grounds\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 3\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=3, passes=80)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.048*\"park\" + 0.029*\"place\" + 0.020*\"water\" + 0.020*\"lots\" + 0.020*\"homeless\" + 0.020*\"parents\" + 0.010*\"sit\" + 0.010*\"garbage\" + 0.010*\"years\" + 0.010*\"covid\"'),\n",
       " (1,\n",
       "  '0.037*\"park\" + 0.037*\"views\" + 0.037*\"theres\" + 0.025*\"day\" + 0.025*\"bit\" + 0.025*\"visitors\" + 0.025*\"cool\" + 0.013*\"area\" + 0.013*\"play\" + 0.013*\"river\"'),\n",
       " (2,\n",
       "  '0.037*\"recondition\" + 0.037*\"cans\" + 0.037*\"mode\" + 0.037*\"attachment\" + 0.037*\"blocks\" + 0.037*\"litter\" + 0.019*\"fills\" + 0.019*\"lot\" + 0.019*\"row\" + 0.019*\"parking\"'),\n",
       " (3,\n",
       "  '0.115*\"park\" + 0.025*\"entrance\" + 0.025*\"kids\" + 0.019*\"area\" + 0.019*\"water\" + 0.013*\"walk\" + 0.013*\"years\" + 0.013*\"tables\" + 0.013*\"note\" + 0.013*\"boulevard\"'),\n",
       " (4,\n",
       "  '0.038*\"space\" + 0.038*\"soccer\" + 0.020*\"picnic\" + 0.020*\"family\" + 0.020*\"city\" + 0.020*\"location\" + 0.020*\"spaces\" + 0.020*\"players\" + 0.020*\"race\" + 0.020*\"fields\"'),\n",
       " (5,\n",
       "  '0.041*\"kids\" + 0.041*\"park\" + 0.041*\"water\" + 0.027*\"signs\" + 0.027*\"grounds\" + 0.027*\"parents\" + 0.027*\"care\" + 0.027*\"dissapointing\" + 0.027*\"responsibility\" + 0.027*\"outremont\"'),\n",
       " (6,\n",
       "  '0.074*\"kids\" + 0.032*\"place\" + 0.022*\"water\" + 0.022*\"help\" + 0.022*\"person\" + 0.022*\"use\" + 0.011*\"sit\" + 0.011*\"rest\" + 0.011*\"centers\" + 0.011*\"bathrooms\"'),\n",
       " (7,\n",
       "  '0.037*\"beach\" + 0.019*\"kids\" + 0.019*\"food\" + 0.019*\"option\" + 0.019*\"drinks\" + 0.019*\"access\" + 0.019*\"way\" + 0.019*\"path\" + 0.019*\"pass\" + 0.019*\"choice\"'),\n",
       " (8,\n",
       "  '0.030*\"water\" + 0.022*\"tables\" + 0.022*\"dog\" + 0.015*\"kids\" + 0.015*\"information\" + 0.015*\"problems\" + 0.015*\"pictures\" + 0.015*\"event\" + 0.015*\"description\" + 0.015*\"drones\"'),\n",
       " (9,\n",
       "  '0.042*\"view\" + 0.034*\"point\" + 0.026*\"buildings\" + 0.026*\"theres\" + 0.026*\"walk\" + 0.026*\"park\" + 0.017*\"visit\" + 0.017*\"look\" + 0.017*\"forest\" + 0.017*\"mini\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 10\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=10, passes=80)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns and adjectives from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice things park outdoor areas useful offleash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spend weekend friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>blocks much cleaner much litter trash cans ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>much potiential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>nice park care grounds outremont dissapointing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews\n",
       "3   nice things park outdoor areas useful offleash...\n",
       "26                              spend weekend friends\n",
       "47  blocks much cleaner much litter trash cans ful...\n",
       "57                                    much potiential\n",
       "76  nice park care grounds outremont dissapointing..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg_3 = df_neg\n",
    "data_nouns_adj = pd.DataFrame(df_neg_3['reviews'].apply(nouns_adj))\n",
    "data_nouns_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_noun_adj = CountVectorizer(stop_words = stop_words) # max_df=.8 means \"It ignores terms that appear in more than 80% of the documents\".\n",
    "data_cv_noun_adj = cv_noun_adj.fit_transform(data_nouns_adj['reviews']).toarray()\n",
    "features_noun_adj = cv_noun_adj.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(data_cv_noun_adj , columns = features_noun_adj)\n",
    "term_document_matrix_noun_adj = df3.transpose()\n",
    "term_document_matrix_noun_adj\n",
    "sparse_matrix_noun_adj = scipy.sparse.csr_matrix(term_document_matrix_noun_adj)\n",
    "corpus_noun_adj = matutils.Sparse2Corpus(sparse_matrix_noun_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_noun_adj = corpora.Dictionary([features_noun_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.037*\"park\" + 0.027*\"kids\" + 0.023*\"water\" + 0.017*\"nice\" + 0.017*\"little\" + 0.012*\"good\" + 0.011*\"small\" + 0.010*\"place\" + 0.010*\"great\" + 0.010*\"picnic\"'),\n",
       " (1,\n",
       "  '0.016*\"park\" + 0.014*\"good\" + 0.013*\"nice\" + 0.010*\"small\" + 0.010*\"theres\" + 0.008*\"view\" + 0.007*\"visitors\" + 0.007*\"food\" + 0.007*\"middle\" + 0.007*\"forest\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 2\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=2, passes=80)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.037*\"park\" + 0.031*\"kids\" + 0.022*\"nice\" + 0.020*\"little\" + 0.017*\"good\" + 0.012*\"parents\" + 0.009*\"theres\" + 0.009*\"views\" + 0.009*\"space\" + 0.009*\"water\"'),\n",
       " (1,\n",
       "  '0.022*\"park\" + 0.022*\"small\" + 0.014*\"water\" + 0.012*\"great\" + 0.011*\"view\" + 0.011*\"nice\" + 0.010*\"kids\" + 0.009*\"point\" + 0.009*\"good\" + 0.008*\"bad\"'),\n",
       " (2,\n",
       "  '0.024*\"park\" + 0.015*\"nice\" + 0.014*\"good\" + 0.013*\"water\" + 0.012*\"picnic\" + 0.012*\"tables\" + 0.012*\"little\" + 0.010*\"area\" + 0.010*\"place\" + 0.008*\"entrance\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 3\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=3, passes=80)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"nice\" + 0.024*\"water\" + 0.016*\"kids\" + 0.016*\"place\" + 0.016*\"station\" + 0.008*\"middle\" + 0.008*\"montreal\" + 0.008*\"green\" + 0.008*\"train\" + 0.008*\"spot\"'),\n",
       " (1,\n",
       "  '0.039*\"park\" + 0.032*\"good\" + 0.024*\"views\" + 0.016*\"little\" + 0.016*\"bit\" + 0.016*\"visitors\" + 0.016*\"way\" + 0.016*\"forest\" + 0.016*\"water\" + 0.008*\"bad\"'),\n",
       " (2,\n",
       "  '0.033*\"view\" + 0.033*\"point\" + 0.025*\"small\" + 0.017*\"good\" + 0.017*\"person\" + 0.017*\"help\" + 0.017*\"use\" + 0.017*\"forest\" + 0.017*\"food\" + 0.017*\"beach\"'),\n",
       " (3,\n",
       "  '0.037*\"park\" + 0.022*\"area\" + 0.022*\"entrance\" + 0.016*\"little\" + 0.016*\"good\" + 0.016*\"picnic\" + 0.016*\"tables\" + 0.016*\"small\" + 0.011*\"careful\" + 0.011*\"walk\"'),\n",
       " (4,\n",
       "  '0.018*\"good\" + 0.014*\"nice\" + 0.014*\"day\" + 0.014*\"information\" + 0.014*\"bad\" + 0.014*\"kids\" + 0.014*\"park\" + 0.009*\"french\" + 0.009*\"description\" + 0.009*\"drones\"'),\n",
       " (5,\n",
       "  '0.038*\"park\" + 0.022*\"nice\" + 0.022*\"water\" + 0.016*\"walk\" + 0.016*\"kids\" + 0.011*\"place\" + 0.011*\"look\" + 0.011*\"concrete\" + 0.011*\"visit\" + 0.011*\"years\"'),\n",
       " (6,\n",
       "  '0.031*\"rest\" + 0.017*\"park\" + 0.016*\"kids\" + 0.016*\"place\" + 0.016*\"clean\" + 0.016*\"path\" + 0.016*\"lachine\" + 0.016*\"bicycle\" + 0.016*\"alongside\" + 0.016*\"hangout\"'),\n",
       " (7,\n",
       "  '0.045*\"small\" + 0.023*\"french\" + 0.023*\"litter\" + 0.023*\"bcbg\" + 0.023*\"attachment\" + 0.023*\"recondition\" + 0.023*\"cleaner\" + 0.023*\"mode\" + 0.023*\"trash\" + 0.023*\"blocks\"'),\n",
       " (8,\n",
       "  '0.035*\"kids\" + 0.035*\"park\" + 0.028*\"nice\" + 0.028*\"water\" + 0.028*\"grounds\" + 0.021*\"picnic\" + 0.021*\"useful\" + 0.021*\"space\" + 0.014*\"little\" + 0.014*\"signs\"'),\n",
       " (9,\n",
       "  '0.072*\"park\" + 0.037*\"great\" + 0.037*\"nice\" + 0.025*\"kids\" + 0.025*\"small\" + 0.013*\"dog\" + 0.013*\"live\" + 0.013*\"area\" + 0.013*\"garbage\" + 0.013*\"option\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 10\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=10, passes=80)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying on all the reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(r\"C:\\Users\\Abhay Mahajan\\Downloads\\ParkReviewsLang.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>https://www.google.com/maps/contrib/1001449741...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.211296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>One of the nicest entry points to this invitin...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB</td>\n",
       "      <td>Nate Neel</td>\n",
       "      <td>https://www.google.com/maps/contrib/1121030547...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.212245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Waterfront to fish or just relax, great place ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB</td>\n",
       "      <td>Yucel Salimoglu</td>\n",
       "      <td>https://www.google.com/maps/contrib/1034180738...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.213178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Everything except the parking is good here.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE</td>\n",
       "      <td>COCO BEADZ</td>\n",
       "      <td>https://www.google.com/maps/contrib/1036060504...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.214115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Defenely the best park in Montreal East, Tetre...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB</td>\n",
       "      <td>Anna Maria Fiore</td>\n",
       "      <td>https://www.google.com/maps/contrib/1016779009...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.215069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>It's so peaceful and happy place near the water</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNpOWJHZ0lREAE</td>\n",
       "      <td>John Ronald C茅sar</td>\n",
       "      <td>https://www.google.com/maps/contrib/1058840136...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.216203</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Niceグ</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSURraTZQc1hREAE</td>\n",
       "      <td>sebastien geoffrion</td>\n",
       "      <td>https://www.google.com/maps/contrib/1028952244...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.217132</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Great view, clean and young children friendly.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNncE5iNER3EAE</td>\n",
       "      <td>小 小懈写</td>\n",
       "      <td>https://www.google.com/maps/contrib/1009950037...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.218052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Super!!!</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUMwc0lTUC1BRRAB</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>https://www.google.com/maps/contrib/1158598595...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.218970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Great to relax alone or with family!</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURBXzUtdXF3RRAB</td>\n",
       "      <td>Alexandre</td>\n",
       "      <td>https://www.google.com/maps/contrib/1032303720...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.220022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Great park. It's very quiet and peaceful.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        review_for  \\\n",
       "0           0  Parc de la Capture-d'Ethan-Allen   \n",
       "1           1  Parc de la Capture-d'Ethan-Allen   \n",
       "2           2  Parc de la Capture-d'Ethan-Allen   \n",
       "3           3  Parc de la Capture-d'Ethan-Allen   \n",
       "4           4  Parc de la Capture-d'Ethan-Allen   \n",
       "5           5  Parc de la Capture-d'Ethan-Allen   \n",
       "6           6  Parc de la Capture-d'Ethan-Allen   \n",
       "7           7  Parc de la Capture-d'Ethan-Allen   \n",
       "8           8  Parc de la Capture-d'Ethan-Allen   \n",
       "9           9  Parc de la Capture-d'Ethan-Allen   \n",
       "\n",
       "                              review_id             username  \\\n",
       "0  ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB              Claudia   \n",
       "1  ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB            Nate Neel   \n",
       "2  ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB      Yucel Salimoglu   \n",
       "3   ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE           COCO BEADZ   \n",
       "4  ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB     Anna Maria Fiore   \n",
       "5   ChZDSUhNMG9nS0VJQ0FnSUNpOWJHZ0lREAE    John Ronald C茅sar   \n",
       "6   ChZDSUhNMG9nS0VJQ0FnSURraTZQc1hREAE  sebastien geoffrion   \n",
       "7   ChZDSUhNMG9nS0VJQ0FnSUNncE5iNER3EAE           小 小懈写   \n",
       "8  ChdDSUhNMG9nS0VJQ0FnSUMwc0lTUC1BRRAB             Nathalie   \n",
       "9  ChdDSUhNMG9nS0VJQ0FnSURBXzUtdXF3RRAB            Alexandre   \n",
       "\n",
       "                                            user_url      published  \\\n",
       "0  https://www.google.com/maps/contrib/1001449741...   7 months ago   \n",
       "1  https://www.google.com/maps/contrib/1121030547...   8 months ago   \n",
       "2  https://www.google.com/maps/contrib/1034180738...  11 months ago   \n",
       "3  https://www.google.com/maps/contrib/1036060504...     a year ago   \n",
       "4  https://www.google.com/maps/contrib/1016779009...     a year ago   \n",
       "5  https://www.google.com/maps/contrib/1058840136...   7 months ago   \n",
       "6  https://www.google.com/maps/contrib/1028952244...     a year ago   \n",
       "7  https://www.google.com/maps/contrib/1009950037...    3 years ago   \n",
       "8  https://www.google.com/maps/contrib/1158598595...     a year ago   \n",
       "9  https://www.google.com/maps/contrib/1032303720...    3 years ago   \n",
       "\n",
       "               date_retrieved  num_stars  num_reviews  \\\n",
       "0  2021-06-20 22:04:09.211296        4.0        107.0   \n",
       "1  2021-06-20 22:04:09.212245        5.0        121.0   \n",
       "2  2021-06-20 22:04:09.213178        4.0         79.0   \n",
       "3  2021-06-20 22:04:09.214115        4.0        128.0   \n",
       "4  2021-06-20 22:04:09.215069        5.0         39.0   \n",
       "5  2021-06-20 22:04:09.216203        5.0         33.0   \n",
       "6  2021-06-20 22:04:09.217132        4.0         24.0   \n",
       "7  2021-06-20 22:04:09.218052        5.0          4.0   \n",
       "8  2021-06-20 22:04:09.218970        4.0         30.0   \n",
       "9  2021-06-20 22:04:09.220022        5.0         56.0   \n",
       "\n",
       "                                         review_text lang  \n",
       "0  One of the nicest entry points to this invitin...   en  \n",
       "1  Waterfront to fish or just relax, great place ...   en  \n",
       "2        Everything except the parking is good here.   en  \n",
       "3  Defenely the best park in Montreal East, Tetre...   en  \n",
       "4    It's so peaceful and happy place near the water   en  \n",
       "5                                             Niceグ   en  \n",
       "6     Great view, clean and young children friendly.   en  \n",
       "7                                           Super!!!   en  \n",
       "8               Great to relax alone or with family!   en  \n",
       "9          Great park. It's very quiet and peaceful.   en  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23032, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_eng = df_all[df_all['lang'] == 'en']\n",
    "df_all_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_neg = df_all_eng[df_all_eng['num_stars'] < 4]\n",
    "df_all_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying nouns function Attempt#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_neg = pd.DataFrame(df_all_neg['review_text'].apply(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_noun = CountVectorizer(stop_words = stop_words)\n",
    "data_cv_noun = cv_noun.fit_transform(df_all_neg['review_text']).toarray()\n",
    "features_noun = cv_noun.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248, 2506)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cv_noun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame(data_cv_noun , columns = features_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document_matrix_noun = df5.transpose()\n",
    "term_document_matrix_noun\n",
    "sparse_matrix_noun = scipy.sparse.csr_matrix(term_document_matrix_noun)\n",
    "corpus_noun = matutils.Sparse2Corpus(sparse_matrix_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_noun = corpora.Dictionary([features_noun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.056*\"park\" + 0.042*\"place\" + 0.020*\"parc\" + 0.020*\"nice\" + 0.017*\"water\" + 0.014*\"kids\" + 0.012*\"google\" + 0.010*\"fountain\" + 0.009*\"day\" + 0.009*\"original\"'),\n",
       " (1,\n",
       "  '0.085*\"park\" + 0.025*\"kids\" + 0.012*\"area\" + 0.011*\"google\" + 0.010*\"nice\" + 0.010*\"dogs\" + 0.009*\"dog\" + 0.009*\"trees\" + 0.009*\"city\" + 0.009*\"playground\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 2\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=2, passes=40)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.097*\"park\" + 0.036*\"place\" + 0.032*\"kids\" + 0.021*\"water\" + 0.014*\"lots\" + 0.012*\"summer\" + 0.010*\"parking\" + 0.009*\"dog\" + 0.009*\"pool\" + 0.009*\"trees\"'),\n",
       " (1,\n",
       "  '0.074*\"park\" + 0.038*\"nice\" + 0.023*\"parc\" + 0.022*\"area\" + 0.015*\"space\" + 0.014*\"kids\" + 0.012*\"day\" + 0.011*\"bit\" + 0.010*\"fountain\" + 0.010*\"dogs\"'),\n",
       " (2,\n",
       "  '0.037*\"google\" + 0.034*\"original\" + 0.025*\"place\" + 0.022*\"park\" + 0.011*\"garbage\" + 0.011*\"great\" + 0.008*\"parks\" + 0.008*\"fun\" + 0.007*\"spot\" + 0.007*\"baseball\"')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 3\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=3, passes=40)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.113*\"place\" + 0.067*\"park\" + 0.038*\"nice\" + 0.029*\"water\" + 0.022*\"kids\" + 0.019*\"bit\" + 0.016*\"montreal\" + 0.016*\"houses\" + 0.015*\"family\" + 0.015*\"lots\"'),\n",
       " (1,\n",
       "  '0.053*\"park\" + 0.027*\"kids\" + 0.021*\"years\" + 0.020*\"fountain\" + 0.017*\"place\" + 0.016*\"parks\" + 0.014*\"pool\" + 0.013*\"great\" + 0.011*\"grass\" + 0.011*\"suit\"'),\n",
       " (2,\n",
       "  '0.068*\"lots\" + 0.054*\"space\" + 0.044*\"garbage\" + 0.020*\"squirrels\" + 0.020*\"dirty\" + 0.019*\"pretty\" + 0.018*\"slide\" + 0.017*\"event\" + 0.017*\"walking\" + 0.016*\"square\"'),\n",
       " (3,\n",
       "  '0.089*\"google\" + 0.080*\"original\" + 0.062*\"parc\" + 0.036*\"park\" + 0.026*\"cool\" + 0.025*\"great\" + 0.017*\"tennis\" + 0.015*\"super\" + 0.014*\"summer\" + 0.013*\"play\"'),\n",
       " (4,\n",
       "  '0.154*\"park\" + 0.034*\"dog\" + 0.026*\"dogs\" + 0.015*\"area\" + 0.015*\"beautiful\" + 0.014*\"food\" + 0.013*\"small\" + 0.013*\"place\" + 0.011*\"path\" + 0.010*\"street\"'),\n",
       " (5,\n",
       "  '0.109*\"park\" + 0.034*\"trees\" + 0.029*\"parking\" + 0.028*\"playground\" + 0.026*\"baseball\" + 0.025*\"water\" + 0.024*\"kids\" + 0.023*\"lot\" + 0.019*\"field\" + 0.018*\"soccer\"'),\n",
       " (6,\n",
       "  '0.035*\"area\" + 0.021*\"ice\" + 0.021*\"night\" + 0.016*\"court\" + 0.015*\"children\" + 0.015*\"basketball\" + 0.015*\"parc\" + 0.014*\"dirt\" + 0.014*\"sun\" + 0.014*\"way\"'),\n",
       " (7,\n",
       "  '0.043*\"ok\" + 0.031*\"view\" + 0.029*\"park\" + 0.026*\"correct\" + 0.022*\"river\" + 0.022*\"fun\" + 0.021*\"city\" + 0.019*\"run\" + 0.013*\"montreal\" + 0.013*\"trails\"'),\n",
       " (8,\n",
       "  '0.021*\"park\" + 0.017*\"cans\" + 0.015*\"winter\" + 0.014*\"trash\" + 0.013*\"football\" + 0.013*\"beach\" + 0.012*\"times\" + 0.011*\"il\" + 0.011*\"mais\" + 0.011*\"garbage\"'),\n",
       " (9,\n",
       "  '0.126*\"park\" + 0.111*\"kids\" + 0.109*\"nice\" + 0.029*\"day\" + 0.025*\"fountain\" + 0.017*\"dogs\" + 0.016*\"cute\" + 0.015*\"money\" + 0.013*\"walks\" + 0.011*\"plate\"')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 10\n",
    "lda_noun = models.LdaModel(corpus=corpus_noun, id2word=id2word_noun, num_topics=10, passes=40)\n",
    "lda_noun.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Nouns and Adjectives Function & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_neg = df_all_eng[df_all_eng['num_stars'] < 4]\n",
    "df_all_neg = pd.DataFrame(df_all_neg['review_text'].apply(nouns_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_neg['review_text'] = df_all_neg['review_text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>beer st-laurenc ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tr猫 beau me pouvoir descendr au bord pour baig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>park squar nice place bu cool shade few seat a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>field uneven risk player hous OK conveni users...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_text\n",
       "13                                 beer st-laurenc ok\n",
       "15                                            correct\n",
       "18  tr猫 beau me pouvoir descendr au bord pour baig...\n",
       "23  park squar nice place bu cool shade few seat a...\n",
       "30  field uneven risk player hous OK conveni users..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_stop_words = ['translated' , 'googl']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_noun_adj = CountVectorizer(stop_words = stop_words)\n",
    "data_cv_noun_adj = cv_noun_adj.fit_transform(df_all_neg['review_text']).toarray()\n",
    "features_noun_adj = cv_noun_adj.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2248, 2615)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cv_noun_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame(data_cv_noun_adj , columns = features_noun_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document_matrix_noun_adj = df6.transpose()\n",
    "term_document_matrix_noun_adj\n",
    "sparse_matrix_noun_adj = scipy.sparse.csr_matrix(term_document_matrix_noun_adj)\n",
    "corpus_noun_adj = matutils.Sparse2Corpus(sparse_matrix_noun_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_noun_adj = corpora.Dictionary([features_noun_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.096*\"park\" + 0.041*\"nice\" + 0.028*\"place\" + 0.019*\"kid\" + 0.016*\"peopl\" + 0.016*\"good\" + 0.014*\"water\" + 0.013*\"lot\" + 0.013*\"dog\" + 0.012*\"small\"'),\n",
       " (1,\n",
       "  '0.020*\"origin\" + 0.017*\"parc\" + 0.012*\"great\" + 0.011*\"kid\" + 0.009*\"cool\" + 0.009*\"mani\" + 0.008*\"field\" + 0.008*\"basebal\" + 0.007*\"park\" + 0.007*\"fun\"')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 2\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=2, passes=10)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.028279613643649"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.coherencemodel.CoherenceModel(corpus = corpus_noun_adj , model=lda_noun_adj, coherence='u_mass').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"good\" + 0.015*\"cool\" + 0.015*\"lot\" + 0.014*\"place\" + 0.012*\"parc\" + 0.011*\"nice\" + 0.011*\"kid\" + 0.010*\"green\" + 0.009*\"trash\" + 0.009*\"care\"'),\n",
       " (1,\n",
       "  '0.095*\"park\" + 0.042*\"nice\" + 0.030*\"place\" + 0.019*\"kid\" + 0.018*\"water\" + 0.016*\"small\" + 0.015*\"dog\" + 0.014*\"origin\" + 0.012*\"mani\" + 0.012*\"peopl\"'),\n",
       " (2,\n",
       "  '0.054*\"park\" + 0.018*\"ok\" + 0.017*\"great\" + 0.016*\"lot\" + 0.015*\"peopl\" + 0.015*\"kid\" + 0.011*\"nice\" + 0.009*\"day\" + 0.009*\"fun\" + 0.009*\"garbag\"')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 3\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=3, passes=40)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.762279960992049"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.coherencemodel.CoherenceModel(corpus = corpus_noun_adj , model=lda_noun_adj, coherence='u_mass').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.046*\"dog\" + 0.037*\"park\" + 0.037*\"good\" + 0.033*\"ok\" + 0.028*\"parc\" + 0.026*\"place\" + 0.015*\"area\" + 0.015*\"great\" + 0.013*\"day\" + 0.011*\"kid\"'),\n",
       " (1,\n",
       "  '0.088*\"park\" + 0.048*\"peopl\" + 0.043*\"kid\" + 0.029*\"nice\" + 0.018*\"mani\" + 0.017*\"water\" + 0.015*\"lot\" + 0.013*\"parc\" + 0.013*\"homeless\" + 0.012*\"place\"'),\n",
       " (2,\n",
       "  '0.032*\"park\" + 0.019*\"time\" + 0.017*\"beauti\" + 0.017*\"better\" + 0.014*\"littl\" + 0.013*\"bench\" + 0.012*\"year\" + 0.011*\"tree\" + 0.011*\"horribl\" + 0.010*\"place\"'),\n",
       " (3,\n",
       "  '0.085*\"nice\" + 0.070*\"park\" + 0.043*\"place\" + 0.030*\"small\" + 0.016*\"littl\" + 0.013*\"kid\" + 0.012*\"view\" + 0.011*\"good\" + 0.011*\"walk\" + 0.010*\"fountain\"'),\n",
       " (4,\n",
       "  '0.046*\"origin\" + 0.034*\"park\" + 0.028*\"great\" + 0.026*\"field\" + 0.022*\"good\" + 0.019*\"cool\" + 0.016*\"place\" + 0.015*\"soccer\" + 0.014*\"basebal\" + 0.012*\"spot\"'),\n",
       " (5,\n",
       "  '0.087*\"park\" + 0.026*\"nice\" + 0.020*\"lot\" + 0.017*\"bad\" + 0.017*\"kid\" + 0.014*\"clean\" + 0.014*\"pool\" + 0.013*\"water\" + 0.013*\"dirti\" + 0.012*\"garbag\"')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 6\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=6, passes=40)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.810201413275126"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.coherencemodel.CoherenceModel(corpus = corpus_noun_adj , model=lda_noun_adj, coherence='u_mass').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.089*\"park\" + 0.087*\"nice\" + 0.044*\"origin\" + 0.035*\"place\" + 0.028*\"ok\" + 0.028*\"lot\" + 0.022*\"cool\" + 0.021*\"clean\" + 0.016*\"littl\" + 0.015*\"space\"'),\n",
       " (1,\n",
       "  '0.065*\"park\" + 0.043*\"dog\" + 0.029*\"bad\" + 0.025*\"bit\" + 0.023*\"nice\" + 0.023*\"kid\" + 0.017*\"place\" + 0.014*\"littl\" + 0.014*\"time\" + 0.014*\"young\"'),\n",
       " (2,\n",
       "  '0.072*\"park\" + 0.034*\"place\" + 0.024*\"time\" + 0.021*\"noth\" + 0.018*\"quiet\" + 0.017*\"walk\" + 0.014*\"water\" + 0.013*\"special\" + 0.013*\"calm\" + 0.012*\"care\"'),\n",
       " (3,\n",
       "  '0.056*\"field\" + 0.049*\"park\" + 0.032*\"parc\" + 0.032*\"soccer\" + 0.028*\"beauti\" + 0.024*\"great\" + 0.022*\"basebal\" + 0.020*\"correct\" + 0.019*\"pool\" + 0.019*\"suit\"'),\n",
       " (4,\n",
       "  '0.026*\"area\" + 0.024*\"trail\" + 0.017*\"access\" + 0.016*\"activ\" + 0.016*\"mai\" + 0.014*\"traffic\" + 0.014*\"parc\" + 0.014*\"car\" + 0.013*\"highway\" + 0.012*\"aussi\"'),\n",
       " (5,\n",
       "  '0.086*\"park\" + 0.028*\"nice\" + 0.022*\"kid\" + 0.017*\"winter\" + 0.017*\"skate\" + 0.015*\"picnic\" + 0.014*\"bathroom\" + 0.014*\"great\" + 0.013*\"pool\" + 0.013*\"children\"'),\n",
       " (6,\n",
       "  '0.052*\"water\" + 0.047*\"dirti\" + 0.044*\"park\" + 0.036*\"garbag\" + 0.024*\"trash\" + 0.021*\"super\" + 0.020*\"food\" + 0.020*\"great\" + 0.020*\"river\" + 0.017*\"peopl\"'),\n",
       " (7,\n",
       "  '0.071*\"good\" + 0.031*\"park\" + 0.030*\"mani\" + 0.029*\"place\" + 0.018*\"peopl\" + 0.018*\"fun\" + 0.016*\"nice\" + 0.016*\"big\" + 0.015*\"parc\" + 0.014*\"bench\"'),\n",
       " (8,\n",
       "  '0.057*\"park\" + 0.037*\"small\" + 0.036*\"place\" + 0.031*\"nice\" + 0.027*\"fountain\" + 0.016*\"mani\" + 0.015*\"summer\" + 0.015*\"kid\" + 0.015*\"metro\" + 0.013*\"children\"'),\n",
       " (9,\n",
       "  '0.072*\"park\" + 0.061*\"kid\" + 0.031*\"great\" + 0.025*\"peopl\" + 0.021*\"day\" + 0.020*\"homeless\" + 0.014*\"citi\" + 0.013*\"good\" + 0.012*\"water\" + 0.011*\"weed\"')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Topics = 10\n",
    "lda_noun_adj = models.LdaModel(corpus=corpus_noun_adj, id2word=id2word_noun_adj, num_topics=10, passes=40)\n",
    "lda_noun_adj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.127178567399499"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.coherencemodel.CoherenceModel(corpus = corpus_noun_adj , model=lda_noun_adj, coherence='u_mass').get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
